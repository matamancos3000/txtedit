import pandas as pd
import logging
from pathlib import Path
import unicodedata
import re

# =========================
# LOGGING
# =========================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# =========================
# CONFIGURACI√ìN
# =========================
BASE_PATH = Path("c:/Copia-reporte-Aclarabot")

ACLARABOT_PATH = next(BASE_PATH.glob("*.csv"))  # ej: 06-Jan.csv
ACLARAPP_PATH = BASE_PATH / "Copy-Aclarapp" / "TablaCopiadaDeAclarapp.csv"
AGENTES_PATH = BASE_PATH / "Copy-Aclarapp" / "InfoAgentes.csv"

OUTPUT_FILE = BASE_PATH / "Acumulado_filtrado_11-Dec.csv"

# =========================
# FUNCIONES
# =========================
def normalizar_columna(col):
    col = col.strip()
    col = unicodedata.normalize("NFKD", col)
    col = col.encode("ascii", "ignore").decode("utf-8")
    return col

def cargar_csv(ruta, sep=","):
    df = pd.read_csv(
        ruta,
        sep=sep,
        dtype=str,
        encoding="utf-8-sig",
        on_bad_lines="warn"
    )
    df.columns = [normalizar_columna(c) for c in df.columns]
    df = df.apply(lambda col: col.str.strip() if col.dtype == "object" else col)
    return df

# =========================
# MAIN
# =========================
def main():
    logger.info("üöÄ Iniciando merge ACLARABOT + ACLARAPP + INFOAGENTES")

    # =========================
    # CARGA ARCHIVOS
    # =========================
    aclarabot_df = cargar_csv(ACLARABOT_PATH)
    logger.info(f"‚úì Aclarabot cargado: {ACLARABOT_PATH.name} ({len(aclarabot_df)} filas)")
    
    # DEBUG: Mostrar primeras filas y formato de fecha
    if "Fecha" in aclarabot_df.columns:
        logger.info(f"  Ejemplos de formato 'Fecha' en Aclarabot:")
        for i in range(min(3, len(aclarabot_df))):
            logger.info(f"    Fila {i}: {aclarabot_df['Fecha'].iloc[i]}")

    aclarapp_df = cargar_csv(ACLARAPP_PATH, sep="|")
    logger.info(f"‚úì Aclarapp cargado ({len(aclarapp_df)} filas)")

    agentes_df = cargar_csv(AGENTES_PATH, sep="|")
    logger.info(f"‚úì InfoAgentes cargado ({len(agentes_df)} filas)")

    # =========================
    # AJUSTES DE COLUMNAS
    # =========================
    if "CIS" in aclarapp_df.columns:
        aclarapp_df.rename(columns={"CIS": "CIS_2"}, inplace=True)

    # =========================
    # MERGE 1: ACLARABOT + ACLARAPP
    # =========================
    merge_1 = aclarabot_df.merge(
        aclarapp_df,
        how="left",
        left_on="AclaracionID",
        right_on="ID Aclaracion",
        suffixes=("", "_DUP"),
        indicator=True
    )

    logger.info(f"Merge Aclarapp: {merge_1['_merge'].value_counts().to_dict()}")
    merge_1.drop(columns=["_merge"], inplace=True)

    # =========================
    # MERGE 2: + INFOAGENTES
    # =========================
    df_final = merge_1.merge(
        agentes_df,
        how="left",
        left_on="Numero de registro",
        right_on="ID",
        suffixes=("", "_AGENTE"),
        indicator=True
    )

    logger.info(f"Merge Agentes: {df_final['_merge'].value_counts().to_dict()}")
    df_final.drop(columns=["_merge"], inplace=True)

    # =========================
    # NORMALIZAR TODAS LAS COLUMNAS DE FECHA A FORMATO 24 HORAS
    # =========================
    logger.info("üîÑ Normalizando columnas de fecha a formato 24h...")
    
    columnas_fecha = [
        "Fecha", 
        "Fecha Creaci√≥n", 
        "Fecha Enviado", 
        "Fecha Asignacion", 
        "Fecha Atendido"
    ]
    
    for col in columnas_fecha:
        if col in df_final.columns:
            logger.info(f"  Procesando columna: {col}")
            
            # Contar valores no nulos antes
            valores_originales = df_final[col].notna().sum()
            logger.info(f"    Valores no nulos originales: {valores_originales}")
            
            if valores_originales > 0:
                # Mostrar algunos ejemplos del formato original
                ejemplos = df_final[col].dropna().head(3).tolist()
                logger.info(f"    Ejemplos de formato original: {ejemplos}")
            
            # PRIMERO: Limpiar y normalizar el formato
            # 1. Reemplazar puntos por dos puntos en la parte de tiempo (hh.mm.ss -> hh:mm:ss)
            def limpiar_formato_fecha(valor):
                if pd.isna(valor):
                    return valor
                
                valor_str = str(valor).strip()
                
                # Si el valor ya est√° vac√≠o, regresar
                if not valor_str or valor_str.lower() in ['nan', 'nat', 'null', 'none']:
                    return valor
                
                # Reemplazar puntos por dos puntos SOLO en la parte de tiempo
                # Patr√≥n: d√≠gitos.d√≠gitos.d√≠gitos (hh.mm.ss)
                if '.' in valor_str:
                    # Separar por espacios
                    partes = valor_str.split()
                    if len(partes) >= 2:
                        # Buscar la parte que tiene d√≠gitos.puntos.d√≠gitos
                        for i, parte in enumerate(partes):
                            if re.match(r'\d{1,2}\.\d{1,2}\.\d{1,2}', parte):
                                # Reemplazar puntos por dos puntos
                                partes[i] = parte.replace('.', ':')
                                break
                    
                        # Unir de nuevo
                        valor_str = ' '.join(partes)
                
                # 2. Normalizar AM/PM (p.m. -> PM, a.m. -> AM)
                valor_str = re.sub(r'\bp\.?m\.?\b', 'PM', valor_str, flags=re.IGNORECASE)
                valor_str = re.sub(r'\ba\.?m\.?\b', 'AM', valor_str, flags=re.IGNORECASE)
                
                return valor_str
            
            # Aplicar limpieza
            df_final[col] = df_final[col].apply(limpiar_formato_fecha)
            
            # SEGUNDO: Convertir a datetime
            try:
                # Intentar varios formatos
                df_final[col] = pd.to_datetime(
                    df_final[col],
                    format="%d/%m/%Y %I:%M:%S %p",  # Formato con AM/PM
                    errors="coerce"
                )
                
                # Si no funciona, intentar sin formato espec√≠fico
                if df_final[col].isna().all() or df_final[col].isna().sum() == valores_originales:
                    logger.info(f"    Intentando parseo autom√°tico...")
                    df_final[col] = pd.to_datetime(
                        df_final[col],
                        dayfirst=True,  # Importante para dd/mm/yyyy
                        errors="coerce"
                    )
                
            except Exception as e:
                logger.error(f"    Error convirtiendo {col}: {e}")
                df_final[col] = pd.to_datetime(df_final[col], errors="coerce")
            
            # Verificar conversi√≥n
            nulos = df_final[col].isna().sum()
            convertidas = valores_originales - nulos
            logger.info(f"    Fechas convertidas: {convertidas}/{valores_originales}")
            
            if nulos > 0 and nulos < 10:
                # Mostrar algunas fechas problem√°ticas
                fechas_problematicas = df_final.loc[df_final[col].isna(), col].head(5).tolist()
                logger.warning(f"    Ejemplos de fechas no convertidas: {fechas_problematicas}")

    # =========================
    # ORDENAR POR FECHA (de m√°s antigua a m√°s actual)
    # =========================
    if "Fecha" in df_final.columns:
        logger.info(f"üìÖ Ordenando por columna 'Fecha' (de m√°s antigua a m√°s actual)")
        
        # Verificar si tenemos fechas v√°lidas
        fechas_validas = df_final["Fecha"].notna().sum()
        logger.info(f"  Fechas v√°lidas para ordenar: {fechas_validas}/{len(df_final)}")
        
        if fechas_validas > 0:
            # Crear copia temporal para ordenar
            df_final["_temp_orden"] = df_final["Fecha"]
            
            # Ordenar (los NaN/NaT van al final por defecto)
            df_final.sort_values("_temp_orden", inplace=True, na_position="last")
            
            # Eliminar columna temporal
            df_final.drop("_temp_orden", axis=1, inplace=True)
            
            # Verificar ordenamiento
            primera_fecha = df_final["Fecha"].iloc[0] if fechas_validas > 0 else None
            ultima_fecha_valida_idx = df_final["Fecha"].last_valid_index()
            ultima_fecha = df_final["Fecha"].loc[ultima_fecha_valida_idx] if ultima_fecha_valida_idx else None
            
            logger.info(f"  Primera fecha: {primera_fecha}")
            logger.info(f"  √öltima fecha v√°lida: {ultima_fecha}")
        else:
            logger.warning("  No hay fechas v√°lidas para ordenar")
    else:
        logger.warning("‚ö†Ô∏è No se encontr√≥ columna 'Fecha' para ordenar")

    # =========================
    # FORMATEAR FECHAS PARA SALIDA (opcional)
    # =========================
    # Convertir a string con formato 24h para el CSV
    for col in columnas_fecha:
        if col in df_final.columns:
            # Formatear solo las fechas no nulas
            mask = df_final[col].notna()
            df_final.loc[mask, col] = df_final.loc[mask, col].dt.strftime("%d/%m/%Y %H:%M:%S")

    # =========================
    # EXPORTAR CSV
    # =========================
    df_final.to_csv(
        OUTPUT_FILE,
        index=False,
        encoding="utf-8-sig"
    )

    logger.info("‚úÖ Archivo generado correctamente")
    logger.info(f"üìÑ {OUTPUT_FILE}")
    logger.info(f"üìä Total filas: {len(df_final)}")
    
    # Resumen de columnas de fecha
    logger.info("üìÖ Resumen final de columnas de fecha:")
    for col in columnas_fecha:
        if col in df_final.columns:
            no_nulos = df_final[col].notna().sum()
            logger.info(f"  {col}: {no_nulos}/{len(df_final)} valores no nulos")

# =========================
# EJECUCI√ìN
# =========================
if __name__ == "__main__":
    main()
