import pandas as pd
import logging
from pathlib import Path
import re
from datetime import datetime
import numpy as np
import unicodedata

# =========================
# LOGGING
# =========================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# =========================
# CONFIGURACI√ìN
# =========================
BASE_PATH = Path("c:/Copia-reporte-Aclarabot")

# Buscar archivo CSV filtrado
CSV_PATTERN = "Acumulado_Filtrado_*.csv"
ARCHIVO_CSV = None
for archivo in BASE_PATH.glob(CSV_PATTERN):
    ARCHIVO_CSV = archivo
    break

if ARCHIVO_CSV is None:
    logger.error(f"No se encontr√≥ archivo {CSV_PATTERN} en {BASE_PATH}")
    exit(1)

# Crear carpeta para archivos Excel
EXCEL_FOLDER = BASE_PATH / "archivos_Excel"
EXCEL_FOLDER.mkdir(exist_ok=True)

# Nombre din√°mico del archivo Excel (en espa√±ol)
meses_es = {
    1: "Enero", 2: "Febrero", 3: "Marzo", 4: "Abril",
    5: "Mayo", 6: "Junio", 7: "Julio", 8: "Agosto",
    9: "Septiembre", 10: "Octubre", 11: "Noviembre", 12: "Diciembre"
}
fecha_hoy = datetime.now()
NOMBRE_EXCEL = f"Reporte_Aclarapp_{fecha_hoy.day}-{meses_es[fecha_hoy.month]}.xlsx"
RUTA_EXCEL = EXCEL_FOLDER / NOMBRE_EXCEL

# =========================
# FUNCIONES
# =========================
def normalizar_texto(texto):
    """Normaliza texto eliminando acentos y convirtiendo a min√∫sculas"""
    if pd.isna(texto):
        return texto
    texto = str(texto)
    # Normalizar unicode y eliminar acentos
    texto = unicodedata.normalize('NFKD', texto)
    texto = ''.join([c for c in texto if not unicodedata.combining(c)])
    return texto.lower().strip()

def limpiar_formato_fecha_especial(valor):
    """
    Limpia formato especial: dd/MM/yyyy hh:mm:ss p. m. (con espacio entre p. y m.)
    y a. m.
    """
    if pd.isna(valor):
        return valor
    
    valor_str = str(valor).strip()
    
    if not valor_str or valor_str.lower() in ['nan', 'nat', 'null', 'none', '']:
        return valor
    
    # Corregir el espacio entre p. y m. / a. y m.
    valor_str = re.sub(r'p\.\s*m\.', 'PM', valor_str, flags=re.IGNORECASE)
    valor_str = re.sub(r'a\.\s*m\.', 'AM', valor_str, flags=re.IGNORECASE)
    
    # Tambi√©n manejar casos con puntos en el tiempo
    valor_str = re.sub(r'(\d{1,2})\.(\d{1,2})\.(\d{1,2})', r'\1:\2:\3', valor_str)
    
    return valor_str.strip()

def parsear_fecha(fecha_str):
    """Convierte string de fecha a datetime"""
    if pd.isna(fecha_str):
        return pd.NaT
    
    # Limpiar formato especial
    fecha_limpia = limpiar_formato_fecha_especial(fecha_str)
    
    # Intentar parsear con diferentes formatos
    try:
        # Formato con AM/PM
        return pd.to_datetime(fecha_limpia, format="%d/%m/%Y %I:%M:%S %p", errors='coerce')
    except:
        try:
            # Formato 24h
            return pd.to_datetime(fecha_limpia, format="%d/%m/%Y %H:%M:%S", errors='coerce')
        except:
            # Parseo autom√°tico
            return pd.to_datetime(fecha_limpia, dayfirst=True, errors='coerce')

def calcular_tiempo_minutos(fecha_inicio, fecha_fin):
    """Calcula diferencia en minutos entre dos fechas"""
    if pd.isna(fecha_inicio) or pd.isna(fecha_fin):
        return np.nan
    
    try:
        diferencia = fecha_fin - fecha_inicio
        # Si la diferencia es negativa, retornar NaN
        if diferencia.total_seconds() < 0:
            return np.nan
        return diferencia.total_seconds() / 60  # Convertir a minutos
    except:
        return np.nan

def encontrar_columna(df, nombres_posibles):
    """Busca una columna en el dataframe considerando diferentes nombres"""
    for nombre in nombres_posibles:
        if nombre in df.columns:
            return nombre
    
    # Si no encuentra directamente, buscar con normalizaci√≥n
    columnas_normalizadas = {normalizar_texto(col): col for col in df.columns}
    for nombre_normalizado in [normalizar_texto(n) for n in nombres_posibles]:
        if nombre_normalizado in columnas_normalizadas:
            return columnas_normalizadas[nombre_normalizado]
    
    return None

# =========================
# MAIN
# =========================
def main():
    logger.info("üöÄ Iniciando generaci√≥n de reporte Excel")
    logger.info(f"üìÇ Archivo fuente: {ARCHIVO_CSV.name}")
    logger.info(f"üìä Archivo destino: {NOMBRE_EXCEL}")
    
    # =========================
    # 1. CARGAR DATOS Y NORMALIZAR NOMBRES DE COLUMNAS
    # =========================
    logger.info("üì• Cargando datos del CSV...")
    
    try:
        df = pd.read_csv(ARCHIVO_CSV, dtype=str, encoding='utf-8-sig')
    except Exception as e:
        logger.error(f"Error al cargar CSV: {e}")
        return
    
    logger.info(f"  Filas originales: {len(df)}")
    logger.info(f"  Columnas encontradas: {len(df.columns)}")
    
    # Mostrar todas las columnas para debugging
    logger.info("  Columnas disponibles en el CSV:")
    for col in df.columns:
        logger.info(f"    - '{col}'")
    
    # Normalizar nombres de columnas (eliminar acentos)
    columnas_originales = df.columns.tolist()
    df.columns = [normalizar_texto(col) for col in df.columns]
    logger.info("  Nombres de columnas normalizados (sin acentos)")
    
    # =========================
    # 2. FILTRAR POR STATUS
    # =========================
    logger.info("üîç Filtrando datos (eliminando Estatus = False)...")
    
    # Buscar columna Estatus
    nombres_estatus = ['estatus', 'status', 'estado']
    columna_estatus = encontrar_columna(df, nombres_estatus)
    
    if columna_estatus:
        filas_antes = len(df)
        df = df[df[columna_estatus] != 'False']
        df = df[df[columna_estatus] != 'false']
        filas_filtradas = filas_antes - len(df)
        logger.info(f"  Filas eliminadas: {filas_filtradas}")
        logger.info(f"  Filas despu√©s de filtrar: {len(df)}")
    else:
        logger.warning("  Columna 'Estatus' no encontrada, continuando sin filtrar")
    
    # =========================
    # 3. ENCONTRAR Y RENOMBRAR COLUMNAS NECESARIAS
    # =========================
    logger.info("üìã Buscando columnas necesarias...")
    
    # Mapeo de nombres normalizados a nombres est√°ndar
    mapeo_columnas = {
        'fecha': 'Fecha',
        'tipo de tarjeta': 'Tipo de tarjeta',
        'tipo de aclaracion': 'Tipo de aclaracion',
        'detalles de aclaracion': 'Detalles de aclaracion',
        'cargos': 'Cargos',
        'robotid': 'RobotID',
        'aclaracionid': 'AclaracionID',
        'estatus': 'Estatus',
        'registro': 'Registro',
        'folio': 'Folio',
        'cis_1': 'CIS_1',
        'fecha creacion': 'Fecha Creaci√≥n',
        'fecha enviado': 'Fecha Enviado',
        'fecha asignacion': 'Fecha Asignacion',
        'fecha atendido': 'Fecha Atendido',
        'nombre': 'Nombre Agente',
        'supervisor': 'Supervisor',
        'site': 'Site',
        'skill': 'Skill'
    }
    
    # Buscar columnas en el dataframe
    columnas_encontradas = {}
    for col_normalizada, col_estandar in mapeo_columnas.items():
        if col_normalizada in df.columns:
            columnas_encontradas[col_estandar] = col_normalizada
            logger.info(f"  ‚úì Encontrada: '{col_normalizada}' -> '{col_estandar}'")
        else:
            logger.warning(f"  ‚úó No encontrada: '{col_estandar}' (buscada como '{col_normalizada}')")
    
    # Verificar especialmente las columnas de fecha
    columnas_fecha_buscadas = ['Fecha', 'Fecha Enviado', 'Fecha Asignacion', 'Fecha Atendido', 'Fecha Creaci√≥n']
    for col_fecha in columnas_fecha_buscadas:
        nombre_normalizado = normalizar_texto(col_fecha)
        if nombre_normalizado in df.columns:
            logger.info(f"  ‚úÖ Columna de fecha '{col_fecha}' encontrada como '{nombre_normalizado}'")
        else:
            logger.warning(f"  ‚ùå Columna de fecha '{col_fecha}' NO encontrada")
    
    # Renombrar columnas encontradas a nombres est√°ndar
    for col_estandar, col_original in columnas_encontradas.items():
        df = df.rename(columns={col_original: col_estandar})
    
    # =========================
    # 4. PROCESAR FECHAS
    # =========================
    logger.info("\n‚è∞ Procesando fechas...")
    
    columnas_fecha = ['Fecha', 'Fecha Creaci√≥n', 'Fecha Enviado', 'Fecha Asignacion', 'Fecha Atendido']
    
    for col in columnas_fecha:
        if col in df.columns:
            logger.info(f"  Procesando '{col}'...")
            
            # Mostrar ejemplos antes de procesar
            valores_no_nulos = df[col].notna().sum()
            logger.info(f"    Valores a procesar: {valores_no_nulos}/{len(df)}")
            
            if valores_no_nulos > 0:
                ejemplos = df[col].dropna().head(3).tolist()
                for i, ejemplo in enumerate(ejemplos):
                    logger.debug(f"    Ejemplo {i}: '{ejemplo}'")
            
            # Procesar fechas
            df[col] = df[col].apply(parsear_fecha)
            
            # Verificar conversi√≥n
            nulos = df[col].isna().sum()
            convertidas = valores_no_nulos - nulos
            logger.info(f"    Convertidas: {convertidas}/{valores_no_nulos} ({convertidas/valores_no_nulos*100:.1f}%)")
            
            if nulos > 0 and nulos < 5:
                ejemplos_no_convertidos = df.loc[df[col].isna(), col].head(3).tolist()
                logger.warning(f"    Ejemplos no convertidos: {ejemplos_no_convertidos}")
        else:
            logger.warning(f"  Columna '{col}' no disponible para procesar")
    
    # =========================
    # 5. CALCULAR TIEMPOS
    # =========================
    logger.info("\n‚è±Ô∏è Calculando tiempos...")
    
    # Tiempo de captura agente (Fecha Enviado - Fecha Creaci√≥n) en minutos
    if 'Fecha Enviado' in df.columns and 'Fecha Creaci√≥n' in df.columns:
        logger.info("  Calculando Tiempo de captura agente...")
        df['Tiempo de captura agente'] = df.apply(
            lambda row: calcular_tiempo_minutos(row['Fecha Creaci√≥n'], row['Fecha Enviado']), axis=1
        )
        
        # Convertir a segundos
        df['Tiempo de captura agente segundos'] = df['Tiempo de captura agente'] * 60
        
        # Estad√≠sticas
        tiempo_prom_captura = df['Tiempo de captura agente'].mean()
        logger.info(f"    ‚úì Tiempo promedio: {tiempo_prom_captura:.2f} minutos")
    else:
        logger.warning("  ‚úó No se pueden calcular tiempos de captura (faltan columnas)")
    
    # Tiempo de alta robot (Fecha - Fecha Asignacion) en minutos
    if 'Fecha' in df.columns and 'Fecha Asignacion' in df.columns:
        logger.info("  Calculando Tiempo de alta robot...")
        df['Tiempo de alta robot'] = df.apply(
            lambda row: calcular_tiempo_minutos(row['Fecha Asignacion'], row['Fecha']), axis=1
        )
        
        # Convertir a segundos
        df['Tiempo de alta robot segundos'] = df['Tiempo de alta robot'] * 60
        
        # Estad√≠sticas
        tiempo_prom_alta = df['Tiempo de alta robot'].mean()
        logger.info(f"    ‚úì Tiempo promedio: {tiempo_prom_alta:.2f} minutos")
    else:
        logger.warning("  ‚úó No se pueden calcular tiempos de alta robot (faltan columnas)")
    
    # Contar n√∫mero de cargos
    if 'Cargos' in df.columns:
        try:
            logger.info("  Calculando n√∫mero de cargos...")
            df['Numero de cargos'] = pd.to_numeric(df['Cargos'], errors='coerce').fillna(0)
            logger.info(f"    ‚úì Cargos calculados: {df['Numero de cargos'].sum():.2f} total")
        except Exception as e:
            df['Numero de cargos'] = 0
            logger.warning(f"    ‚úó Error calculando cargos: {e}")
    
    # =========================
    # 6. RENOMBRAR VALORES
    # =========================
    logger.info("\nüè∑Ô∏è Renombrando valores...")
    
    if 'Estatus' in df.columns:
        filas_antes = df['Estatus'].eq('True').sum()
        df['Estatus'] = df['Estatus'].replace({'True': 'exitoso', 'true': 'exitoso', 'TRUE': 'exitoso'})
        filas_despues = df['Estatus'].eq('exitoso').sum()
        logger.info(f"  'Estatus' actualizado: {filas_antes} True -> {filas_despues} exitoso")
    
    # =========================
    # 7. REORDENAR COLUMNAS FINALES
    # =========================
    logger.info("\nüìä Estructurando columnas finales...")
    
    columnas_finales = [
        'Fecha', 'Tipo de tarjeta', 'Tipo de aclaracion', 'Detalles de aclaracion',
        'Cargos', 'RobotID', 'AclaracionID', 'Estatus', 'Registro', 'Folio',
        'CIS_1', 'Fecha Creaci√≥n', 'Fecha Enviado', 'Fecha Asignacion', 'Fecha Atendido',
        'Tiempo de captura agente', 'Tiempo de alta robot',
        'Tiempo de captura agente segundos', 'Tiempo de alta robot segundos',
        'Numero de cargos', 'Nombre Agente', 'Supervisor', 'Site', 'Skill'
    ]
    
    # Solo mantener columnas que existen
    columnas_finales_existentes = [col for col in columnas_finales if col in df.columns]
    columnas_faltantes = [col for col in columnas_finales if col not in df.columns]
    
    logger.info(f"  Columnas disponibles para el reporte: {len(columnas_finales_existentes)}/{len(columnas_finales)}")
    
    if columnas_faltantes:
        logger.warning("  Columnas faltantes:")
        for col in columnas_faltantes:
            logger.warning(f"    ‚Ä¢ {col}")
    
    df = df[columnas_finales_existentes]
    
    logger.info("\n  Resumen por columna:")
    for col in columnas_finales_existentes:
        no_nulos = df[col].notna().sum()
        porcentaje = no_nulos / len(df) * 100
        logger.info(f"    {col:<30} {no_nulos:>4}/{len(df):<4} ({porcentaje:>5.1f}%)")
    
    # =========================
    # 8. ELIMINAR ARCHIVOS EXCEL ANTERIORES
    # =========================
    logger.info("\nüóëÔ∏è Limpiando archivos Excel anteriores...")
    
    archivos_eliminados = 0
    for archivo_excel in EXCEL_FOLDER.glob("Reporte_Aclarapp_*.xlsx"):
        if archivo_excel.name != NOMBRE_EXCEL:
            try:
                archivo_excel.unlink()
                logger.info(f"  Eliminado: {archivo_excel.name}")
                archivos_eliminados += 1
            except Exception as e:
                logger.warning(f"  No se pudo eliminar {archivo_excel.name}: {e}")
    
    logger.info(f"  Total archivos eliminados: {archivos_eliminados}")
    
    # =========================
    # 9. CREAR ARCHIVO EXCEL
    # =========================
    logger.info(f"\nüíæ Creando archivo Excel: {RUTA_EXCEL}")
    
    try:
        # Crear Excel con pandas
        with pd.ExcelWriter(RUTA_EXCEL, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Reporte', index=False)
            
            # Ajustar ancho de columnas autom√°ticamente
            worksheet = writer.sheets['Reporte']
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if cell.value:
                            max_length = max(max_length, len(str(cell.value)))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                worksheet.column_dimensions[column_letter].width = adjusted_width
        
        logger.info("‚úÖ Reporte Excel generado exitosamente")
        logger.info(f"üìÑ Archivo: {RUTA_EXCEL}")
        logger.info(f"üìä Total registros en reporte: {len(df)}")
        
    except Exception as e:
        logger.error(f"‚ùå Error al crear Excel: {e}")
        # Intentar con formato m√°s simple
        try:
            df.to_excel(RUTA_EXCEL, index=False)
            logger.info("‚úÖ Reporte creado con formato b√°sico")
        except Exception as e2:
            logger.error(f"‚ùå Error cr√≠tico al crear Excel: {e2}")
            return
    
    # =========================
    # 10. RESUMEN FINAL
    # =========================
    logger.info("\n" + "="*70)
    logger.info("üìã RESUMEN FINAL DEL REPORTE")
    logger.info("="*70)
    
    logger.info(f"üìà TOTAL DE REGISTROS: {len(df)}")
    
    if 'Estatus' in df.columns:
        exitosos = df['Estatus'].eq('exitoso').sum()
        otros = len(df) - exitosos
        logger.info(f"\nüìä ESTATUS:")
        logger.info(f"  ‚Ä¢ Exitosos: {exitosos} ({exitosos/len(df)*100:.1f}%)")
        logger.info(f"  ‚Ä¢ Otros: {otros} ({otros/len(df)*100:.1f}%)")
    
    if 'Nombre Agente' in df.columns:
        agentes_unicos = df['Nombre Agente'].nunique()
        logger.info(f"\nüë• AGENTES: {agentes_unicos} √∫nicos")
    
    if 'Tiempo de captura agente' in df.columns:
        tiempo_prom_captura = df['Tiempo de captura agente'].mean()
        tiempo_max_captura = df['Tiempo de captura agente'].max()
        logger.info(f"\n‚è±Ô∏è TIEMPO CAPTURA AGENTE:")
        logger.info(f"  ‚Ä¢ Promedio: {tiempo_prom_captura:.2f} minutos")
        logger.info(f"  ‚Ä¢ M√°ximo: {tiempo_max_captura:.2f} minutos")
    
    if 'Tiempo de alta robot' in df.columns:
        tiempo_prom_alta = df['Tiempo de alta robot'].mean()
        tiempo_max_alta = df['Tiempo de alta robot'].max()
        logger.info(f"\nü§ñ TIEMPO ALTA ROBOT:")
        logger.info(f"  ‚Ä¢ Promedio: {tiempo_prom_alta:.2f} minutos")
        logger.info(f"  ‚Ä¢ M√°ximo: {tiempo_max_alta:.2f} minutos")
    
    if 'Tipo de aclaracion' in df.columns:
        tipos_unicos = df['Tipo de aclaracion'].nunique()
        logger.info(f"\nüìù TIPOS DE ACLARACI√ìN: {tipos_unicos} diferentes")
    
    logger.info("\n" + "="*70)
    logger.info(f"‚úÖ PROCESO COMPLETADO")
    logger.info(f"üìÅ Archivo guardado en: {RUTA_EXCEL}")
    logger.info("="*70)

# =========================
# EJECUCI√ìN
# =========================
if __name__ == "__main__":
    main()
