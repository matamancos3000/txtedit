import re
from pathlib import Path
import urllib.parse
import shutil
import os
import csv

# ================== CONFIGURACI√ìN ==================
# Carpeta ra√≠z que contiene todos los instructivos (con subcarpetas)
CARPETA_RAIZ = Path(r"C:\Users\45056372\Desktop\prueba its\calidad2025")

# Carpeta de recursos (se buscar√° dentro de la ra√≠z)
CARPETA_DE_RECURSOS = "Formatos2021"

# URL base de SharePoint
URL_SHAREPOINT = "https://teams.global.hsbc/sites/labpspyas-2019/CALIDAD20251/"

# Carpeta de salida (se sobrescriben en la misma ra√≠z)
CARPETA_SALIDA = CARPETA_RAIZ

# Log de cambios (una carpeta atr√°s de la ra√≠z)
LOG_CSV = CARPETA_RAIZ.parent / "log_cambios.csv"


# ================== FUNCIONES ==================
def convertir_enlaces(contenido, ruta_html):
    """
    Convierte enlaces dentro de un HTML:
    - Enlaces .htm/.html ‚Üí .pdf en SharePoint (solo si contienen 'calidad2021/').
    - Documentos en Formatos2021 ‚Üí se cambian solo si contienen 'calidad2021/Formatos2021/'.
    - Ignora enlaces a carpetas *_archivos (para no romper im√°genes).
    """
    cambios = []

    def reemplazar_enlace(match):
        comilla = match.group(1)
        enlace = match.group(2)
        enlace_norm = enlace.replace("\\", "/")
        nombre_base, extension = os.path.splitext(os.path.basename(enlace_norm))
        extension = extension.lower()

        # Ignorar si apunta a carpeta de recursos (_archivos)
        if "_archivos/" in enlace_norm or "_archivos\\" in enlace_norm:
            return match.group(0)

        # Caso 1: enlaces a HTML ‚Üí convertirlos en PDF (si contienen calidad2021/)
        if extension in [".htm", ".html"]:
            if "calidad2021/" in enlace_norm.lower():
                partes = enlace_norm.lower().split("calidad2021/", 1)
                if len(partes) == 2:
                    ruta_relativa = Path(partes[1]).with_suffix(".pdf").as_posix()
                    nuevo = f"{URL_SHAREPOINT}{ruta_relativa}"
                    cambios.append((enlace, nuevo, "HTML->PDF"))
                    return f'href={comilla}{nuevo}{comilla}'
            return match.group(0)

        # Caso 2: documentos dentro de calidad2021/Formatos2021/
        elif extension in [".docx", ".pdf", ".xlsx", ".pptx", ".doc", ".xls", ".xlsm"]:
            if "calidad2021/formatos2021/" in enlace_norm.lower():
                partes = enlace_norm.lower().split("calidad2021/formatos2021/", 1)
                if len(partes) == 2:
                    nuevo = f"{URL_SHAREPOINT}{CARPETA_DE_RECURSOS}/{partes[1]}"
                    cambios.append((enlace, nuevo, extension.upper().strip(".")))
                    return f'href={comilla}{nuevo}{comilla}'
            return match.group(0)

        else:
            return match.group(0)

    patron = r'''
        href=
        (["\'])
        ([^"\']+\.(?:htm[l]?|docx|pdf|xlsx|pptx|doc|xls|xlsm))
        \1
    '''

    nuevo_contenido = re.sub(patron, reemplazar_enlace, contenido, flags=re.IGNORECASE | re.VERBOSE)
    return nuevo_contenido, cambios


def procesar_html(html_path):
    """Lee un HTML y convierte enlaces."""
    encoding_detectado = 'utf-8'
    try:
        with open(html_path, 'r', encoding='utf-8') as f:
            contenido = f.read()
    except UnicodeDecodeError:
        encoding_detectado = 'latin-1'
        with open(html_path, 'r', encoding='latin-1') as f:
            contenido = f.read()

    contenido_modificado, cambios = convertir_enlaces(contenido, html_path)
    return contenido_modificado, encoding_detectado, cambios


def copiar_estructura(html_path, output_dir):
    """Copia carpeta de recursos asociada (_archivos)."""
    html_name = html_path.stem
    carpeta_archivos = html_path.parent / f"{html_name}_archivos"

    if carpeta_archivos.exists():
        dest_dir = output_dir / f"{html_name}_archivos"
        shutil.copytree(carpeta_archivos, dest_dir, dirs_exist_ok=True)


def registrar_cambios(archivo_html, cambios):
    """Escribe cambios en el CSV log (sin fecha)."""
    existe = LOG_CSV.exists()
    with open(LOG_CSV, 'a', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        if not existe:
            writer.writerow(["Archivo HTML", "Tipo", "Enlace original", "Enlace nuevo"])
        for original, nuevo, tipo in cambios:
            writer.writerow([archivo_html, tipo, original, nuevo])


# ================== PROCESO PRINCIPAL ==================
print("Iniciando conversi√≥n en carpeta ra√≠z:", CARPETA_RAIZ)

procesados = set()  # Para evitar procesar dos veces el mismo archivo

for html_file in CARPETA_RAIZ.rglob("*.[hH][tT][mM]*"):
    if html_file.is_file() and '_archivos' not in str(html_file.parent) and html_file not in procesados:
        print(f"\n‚óè Procesando: {html_file.relative_to(CARPETA_RAIZ)}")
        procesados.add(html_file)

        cambios = []
        try:
            contenido, encoding_original, cambios = procesar_html(html_file)

            # Guardar el HTML modificado
            html_file.write_text(contenido, encoding=encoding_original)

            # Copiar carpeta de recursos asociada
            copiar_estructura(html_file, html_file.parent)

            if cambios:
                registrar_cambios(str(html_file.relative_to(CARPETA_RAIZ)), cambios)
                print(f"   ‚úÖ {len(cambios)} enlace(s) modificado(s)")
            else:
                print("   ‚ö†Ô∏è No se encontraron enlaces relevantes")

        except Exception as e:
            print(f"   ‚ùå Error en {html_file.name}: {str(e)}")
            if cambios:
                registrar_cambios(str(html_file.relative_to(CARPETA_RAIZ)), cambios)
                print(f"   ‚ö†Ô∏è {len(cambios)} enlace(s) registrados en log pese al error")

print("\n‚úî Proceso completado.")
print("üìë Log de cambios en:", LOG_CSV)
