import os
import re
import csv
from pathlib import Path
from bs4 import BeautifulSoup

# üìå Configuraci√≥n principal
CARPETA_RAIZ = Path(r"../calidad2025")
URL_SHAREPOINT = "https://teams.global.hsbc/sites/labpspyas-2019/CALIDAD20251"

# Archivos de recursos que se deben revisar SOLO si contienen 'calidad2021/formato2021'
EXT_RECURSOS = [".docx", ".pdf", ".xlsx", ".pptx", ".doc", ".xls", ".xlsm"]

# Archivo de log (se guarda un nivel arriba de la carpeta ra√≠z)
LOG_CSV = CARPETA_RAIZ.parent / "log_cambios.csv"

# Para evitar procesar dos veces el mismo archivo en la misma ejecuci√≥n
procesados = set()


def registrar_cambio(nombre_html, tipo, original, nuevo):
    """Guarda un cambio en el CSV de log."""
    with open(LOG_CSV, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([nombre_html, tipo, original, nuevo])


def convertir_enlaces(html_path):
    """Procesa un archivo HTML y actualiza sus enlaces seg√∫n reglas."""
    try:
        # Evitar reprocesar el mismo archivo
        if html_path in procesados:
            return
        procesados.add(html_path)

        with open(html_path, "r", encoding="utf-8", errors="ignore") as f:
            soup = BeautifulSoup(f, "html.parser")

        cambios = False

        for tag in soup.find_all(href=True):
            href = tag["href"]
            original_href = href

            # Regla 1: cambiar .htm/.html a .pdf respetando subcarpetas
            if href.lower().endswith((".htm", ".html")):
                # Obtener ruta relativa desde la carpeta ra√≠z
                rel_path = os.path.relpath((html_path.parent / href).resolve(), CARPETA_RAIZ.resolve())
                rel_path = rel_path.replace("\\", "/")  # Normalizar separadores

                nuevo_href = f"{URL_SHAREPOINT}/{rel_path}"
                nuevo_href = re.sub(r"\.html?$", ".pdf", nuevo_href, flags=re.IGNORECASE)

                if nuevo_href != href:
                    tag["href"] = nuevo_href
                    registrar_cambio(html_path, "HTM->PDF", original_href, nuevo_href)
                    cambios = True

            # Regla 2: recursos (.docx, .pdf, .xlsx, etc.) SOLO si contienen 'calidad2021/formato2021'
            elif any(href.lower().endswith(ext) for ext in EXT_RECURSOS):
                if "calidad2021/formato2021/" in href.lower():
                    nombre_archivo = os.path.basename(href)
                    # Mantener subcarpetas despu√©s de "formato2021"
                    subpath = href.lower().split("calidad2021/formato2021/")[-1]
                    nuevo_href = f"{URL_SHAREPOINT}/Formatos2021/{subpath}"

                    tag["href"] = nuevo_href
                    registrar_cambio(html_path, "RECURSO", original_href, nuevo_href)
                    cambios = True

        # Guardar solo si hubo cambios
        if cambios:
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(str(soup))

    except Exception as e:
        print(f"‚ö†Ô∏è Error procesando {html_path}: {e}")


def recorrer_carpeta(carpeta):
    """Recorre la carpeta y procesa todos los archivos HTML, ignorando *_archivos."""
    for root, dirs, files in os.walk(carpeta):
        # Excluir carpetas *_archivos
        dirs[:] = [d for d in dirs if not d.lower().endswith("_archivos")]

        for file in files:
            if file.lower().endswith((".htm", ".html")):
                file_path = Path(root) / file
                convertir_enlaces(file_path)


def main():
    # Crear log con encabezados si no existe
    if not LOG_CSV.exists():
        with open(LOG_CSV, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["Archivo HTML", "Tipo", "Enlace original", "Enlace nuevo"])

    recorrer_carpeta(CARPETA_RAIZ)
    print("‚úÖ Proceso terminado. Revisar log en:", LOG_CSV)


if __name__ == "__main__":
    main()
