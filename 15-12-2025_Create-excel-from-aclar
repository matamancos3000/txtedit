import os
import pandas as pd
from datetime import datetime
import logging
from pathlib import Path

# =========================
# CONFIGURACI√ìN DE LOGGING
# =========================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# =========================
# CONFIGURACI√ìN GENERAL
# =========================
class Config:
    """Clase para manejar la configuraci√≥n"""
    BASE_PATH = Path("c:/Copia-reporte-Aclarabot")
    ACLARAPP_PATH = BASE_PATH / "Copy-Aclarapp" / "TablaCopiadaDeAclarapp.csv"
    AGENTES_PATH = BASE_PATH / "Copy-Aclarapp" / "InfoAgentes.csv"

    # Mes-a√±o para carpeta y archivo
    MES_ANIO = datetime.now().strftime("%b-%Y")
    OUTPUT_FOLDER = BASE_PATH / "Reporte_Excel" / MES_ANIO
    OUTPUT_FILE = OUTPUT_FOLDER / f"{MES_ANIO}.xlsx"

    # Columnas esperadas para validaci√≥n
    EXPECTED_LOG_COLUMNS = ['AclaracionID', 'Numero de registro']
    EXPECTED_ACLARAPP_COLUMNS = ['ID Aclaraci√≥n']
    EXPECTED_AGENTES_COLUMNS = ['ID']

# =========================
# FUNCIONES AUXILIARES
# =========================
def validar_archivo(ruta_archivo, nombre_archivo):
    if not ruta_archivo.exists():
        raise FileNotFoundError(f"‚ùå No se encontr√≥ el archivo: {nombre_archivo}")
    if ruta_archivo.stat().st_size == 0:
        raise ValueError(f"‚ùå El archivo {nombre_archivo} est√° vac√≠o")
    return True


def cargar_csv_con_validacion(ruta_archivo, sep=',', encoding='utf-8-sig'):
    try:
        df = pd.read_csv(
            ruta_archivo,
            sep=sep,
            encoding=encoding,
            dtype=str,
            on_bad_lines='warn'
        )
        df.columns = df.columns.str.strip()
        df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
        return df
    except Exception as e:
        logger.error(f"Error al cargar {ruta_archivo.name}: {e}")
        raise


def encontrar_columna_similar(df, columna_buscada):
    columna_buscada_lower = columna_buscada.lower()
    for col in df.columns:
        if columna_buscada_lower in col.lower() or col.lower() in columna_buscada_lower:
            logger.warning(f"Usando columna '{col}' en lugar de '{columna_buscada}'")
            return col
    return None


def eliminar_columnas_duplicadas(df, sufijo='_DUP'):
    columnas_a_eliminar = [c for c in df.columns if c.endswith(sufijo)]
    if columnas_a_eliminar:
        logger.info(f"Eliminando {len(columnas_a_eliminar)} columnas duplicadas")
        df.drop(columns=columnas_a_eliminar, inplace=True)
    return df


def verificar_columnas_requeridas(df, columnas_requeridas, nombre_dataset):
    columnas_faltantes = []
    columnas_ajustadas = {}

    for col in columnas_requeridas:
        if col not in df.columns:
            col_similar = encontrar_columna_similar(df, col)
            if col_similar:
                columnas_ajustadas[col] = col_similar
            else:
                columnas_faltantes.append(col)

    if columnas_faltantes:
        logger.error(f"Columnas faltantes en {nombre_dataset}: {columnas_faltantes}")
        return False, columnas_ajustadas

    return True, columnas_ajustadas

# =========================
# FUNCI√ìN PRINCIPAL
# =========================
def generar_reporte():
    try:
        logger.info("üöÄ Iniciando generaci√≥n de reporte...")

        # =========================
        # 1. VALIDAR ARCHIVOS
        # =========================
        validar_archivo(Config.ACLARAPP_PATH, "TablaCopiadaDeAclarapp.csv")
        validar_archivo(Config.AGENTES_PATH, "InfoAgentes.csv")

        archivos_csv = list(Config.BASE_PATH.glob("*.csv"))
        if not archivos_csv:
            raise FileNotFoundError("‚ùå No se encontraron archivos CSV en la carpeta principal")

        logger.info(f"Encontrados {len(archivos_csv)} archivos CSV")

        # =========================
        # 2. LEER LOGS
        # =========================
        logs_dfs = []

        for archivo_csv in archivos_csv:
            try:
                df_log = cargar_csv_con_validacion(archivo_csv)
                logs_dfs.append(df_log)
                logger.info(f"‚úì {archivo_csv.name} cargado ({len(df_log)} registros)")
            except Exception as e:
                logger.warning(f"‚úó No se pudo cargar {archivo_csv.name}: {e}")

        if not logs_dfs:
            raise Exception("‚ùå No se pudieron cargar logs")

        logs_df = pd.concat(logs_dfs, ignore_index=True)

        # =========================
        # 3. VALIDAR COLUMNAS LOGS
        # =========================
        valido, columnas_ajustadas = verificar_columnas_requeridas(
            logs_df,
            Config.EXPECTED_LOG_COLUMNS,
            "Logs"
        )

        if not valido:
            raise ValueError("Faltan columnas requeridas en logs")

        # =========================
        # 4. LEER ACLARAPP
        # =========================
        aclarapp_df = cargar_csv_con_validacion(Config.ACLARAPP_PATH, sep='|')

        valido, _ = verificar_columnas_requeridas(
            aclarapp_df,
            Config.EXPECTED_ACLARAPP_COLUMNS,
            "Aclarapp"
        )

        if not valido:
            raise ValueError("Faltan columnas requeridas en Aclarapp")

        # =========================
        # 5. MERGE LOGS + ACLARAPP
        # =========================
        col_log_id = columnas_ajustadas.get('AclaracionID', 'AclaracionID')

        df_merge_1 = logs_df.merge(
            aclarapp_df,
            how="left",
            left_on=col_log_id,
            right_on="ID Aclaraci√≥n",
            suffixes=("", "_DUP"),
            indicator=True
        )

        logger.info(f"Merge Aclarapp: {df_merge_1['_merge'].value_counts().to_dict()}")
        df_merge_1.drop(columns=['_merge'], inplace=True)
        df_merge_1 = eliminar_columnas_duplicadas(df_merge_1)

        # =========================
        # 6. LEER AGENTES
        # =========================
        agentes_df = cargar_csv_con_validacion(Config.AGENTES_PATH, sep='|')

        valido, _ = verificar_columnas_requeridas(
            agentes_df,
            Config.EXPECTED_AGENTES_COLUMNS,
            "Agentes"
        )

        if not valido:
            raise ValueError("Faltan columnas requeridas en agentes")

        # =========================
        # 7. MERGE CON AGENTES
        # =========================
        col_registro = columnas_ajustadas.get('Numero de registro', 'Numero de registro')

        df_final = df_merge_1.merge(
            agentes_df,
            how="left",
            left_on=col_registro,
            right_on="ID",
            suffixes=("", "_AGENTE_DUP"),
            indicator="merge_agentes"
        )

        logger.info(f"Merge Agentes: {df_final['merge_agentes'].value_counts().to_dict()}")
        df_final.drop(columns=['merge_agentes'], inplace=True)
        df_final = eliminar_columnas_duplicadas(df_final, '_AGENTE_DUP')

        # =========================
        # 8. CREAR CARPETA
        # =========================
        Config.OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)

        # =========================
        # 9. EXPORTAR EXCEL
        # =========================
        logger.info("Exportando a Excel...")

        with pd.ExcelWriter(
            Config.OUTPUT_FILE,
            engine='openpyxl',
            datetime_format='YYYY-MM-DD HH:MM:SS'
        ) as writer:

            df_final.to_excel(
                writer,
                sheet_name='Reporte_Completo',
                index=False
            )

            registros_sin_agente = df_final[df_final['ID'].isna()]
            if not registros_sin_agente.empty:
                registros_sin_agente.to_excel(
                    writer,
                    sheet_name='Sin_Agente_Asignado',
                    index=False
                )

        logger.info("‚úÖ Reporte generado correctamente")
        logger.info(f"üìÇ Carpeta: {Config.OUTPUT_FOLDER}")
        logger.info(f"üìÑ Archivo: {Config.OUTPUT_FILE.name}")
        logger.info(f"üìä Total registros: {len(df_final)}")

    except Exception as e:
        logger.error(f"‚ùå Error durante la generaci√≥n del reporte: {e}")
        raise

# =========================
# EJECUCI√ìN
# =========================
if __name__ == "__main__":
    try:
        generar_reporte()
    except Exception as e:
        logger.error(f"Error fatal: {e}")
        exit(1)
